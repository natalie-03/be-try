name: Dcard Crawler CL3

on:
  push:
    branches:
      - main
  schedule:
    - cron: '0 10 * * *'  # 每天台灣時間 18:00 (UTC+8)

jobs:
  crawler:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install jupyter nbconvert
        pip install undetected-chromedriver selenium webdriver-manager keyboard pandas tqdm

    - name: Convert notebooks to scripts
      run: |
        mkdir -p scripts
        for notebook in $(find . -name "*.ipynb"); do
          base=$(basename "$notebook" .ipynb)
          jupyter nbconvert --to script "$notebook" --output "scripts/$base"
        done

    - name: Run crawler
      run: |
        mkdir -p output
        python scripts/Dcard爬蟲.py   # 你的爬蟲主程式

    - name: Clean CSV
      run: |
        python scripts/Dcard清理.py   # 你的清理程式 (請改成實際檔名)

    - name: Commit scripts and output
      run: |
        git config user.name "github-actions"
        git config user.email "github-actions@github.com"
        git add scripts/*.py output/*.csv
        git commit -m "Auto-update crawler scripts and CSVs" || echo "No changes to commit"
        git push
