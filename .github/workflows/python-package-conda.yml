name: Dcard Crawler CL3

on:
  push:
    branches:
      - main
  schedule:
    - cron: '0 2 * * *'  # 每天 UTC 02:00 自動跑

jobs:
  crawler:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v3
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install undetected-chromedriver selenium webdriver-manager keyboard pandas tqdm

    - name: Convert notebooks to scripts/
      run: |
        mkdir -p scripts
        for notebook in $(find . -name "*.ipynb"); do
          base=$(basename "$notebook" .ipynb)
          jupyter nbconvert --to script "$notebook" --output "scripts/$base"
        done

    - name: Run crawler
      run: |
        mkdir -p output
        python scripts/你的爬蟲檔名.py  # 確保你的爬蟲程式會把 CSV 存到 output/

    - name: Clean CSV
      run: |
        python scripts/你的CSV清理檔.py  # 清理 output/ 裡的 CSV

    - name: Commit scripts and output
      run: |
        git config user.name "github-actions"
        git config user.email "github-actions@github.com"
        git add scripts/*.py output/*.csv
        git commit -m "Auto-update crawler scripts and CSVs" || echo "No changes to commit"
        git push
