{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69586fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall undetected-chromedriver -y\n",
    "!pip install selenium webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6f2fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install undetected-chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef9800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8e756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ec9b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from time import sleep\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ----------------------------\n",
    "# é…ç½®åƒæ•¸\n",
    "# ----------------------------\n",
    "CONFIG = {\n",
    "    \"wait_timeout\": 1,       # é¡¯å¼ç­‰å¾…è¶…æ™‚ (ç§’)\n",
    "    \"short_wait\": 1,         # çŸ­æš«ç­‰å¾… (ç§’)\n",
    "    \"medium_wait\": 1,        # ä¸­ç­‰ç­‰å¾… (ç§’)\n",
    "    \"max_workers\": 5,        # æœ€å¤§ä¸¦ç™¼ç·šç¨‹æ•¸\n",
    "    \"max_scroll\": 1000,      # æœ€å¤šæ»¾å‹•æ¬¡æ•¸\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# è‡ªå‹•åµæ¸¬ Chrome ä¸»ç‰ˆæœ¬\n",
    "# ----------------------------\n",
    "def get_chrome_version():\n",
    "    try:\n",
    "        version = subprocess.check_output(\n",
    "            r'reg query \"HKEY_CURRENT_USER\\Software\\Google\\Chrome\\BLBeacon\" /v version',\n",
    "            shell=True\n",
    "        ).decode(\"utf-8\").strip().split()[-1]\n",
    "        return int(version.split(\".\")[0])\n",
    "    except Exception as e:\n",
    "        print(\"âŒ ç„¡æ³•æª¢æŸ¥ Chrome ç‰ˆæœ¬ï¼Œè«‹ç¢ºèªå·²å®‰è£ Chrome\")\n",
    "        raise e\n",
    "\n",
    "chrome_major_version = get_chrome_version()\n",
    "print(f\"âœ… åµæ¸¬åˆ° Chrome ä¸»ç‰ˆæœ¬è™Ÿ: {chrome_major_version}\")\n",
    "\n",
    "# ----------------------------\n",
    "# å•Ÿå‹•ç€è¦½å™¨\n",
    "# ----------------------------\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "options.add_argument(\"--incognito\")\n",
    "options.add_argument(\"--blink-settings=imagesEnabled=false\")  # ç¦ç”¨åœ–ç‰‡\n",
    "options.add_experimental_option(\"prefs\", {\n",
    "    \"profile.managed_default_content_settings.images\": 2,\n",
    "    \"profile.default_content_setting_values.notifications\": 2\n",
    "})\n",
    "driver = uc.Chrome(version_main=chrome_major_version, options=options)\n",
    "\n",
    "processed_links = set()\n",
    "\n",
    "# ----------------------------\n",
    "# æŠ“å–æ–‡ç« é€£çµ (ç›´åˆ°ä¸‰å¹´å‰)\n",
    "# ----------------------------\n",
    "def get_article_links(driver, board_name, max_scroll=CONFIG[\"max_scroll\"]):\n",
    "    article_links, seen_links = [], set()\n",
    "    driver.get(f\"https://www.dcard.tw/f/{board_name}\")\n",
    "    try:\n",
    "        WebDriverWait(driver, CONFIG[\"wait_timeout\"]).until(\n",
    "            lambda d: d.execute_script(\"return document.readyState\") == \"complete\"\n",
    "        )\n",
    "        sleep(CONFIG[\"medium_wait\"])\n",
    "    except TimeoutException:\n",
    "        print(f\"âš ï¸ {board_name} é é¢åŠ è¼‰è¶…æ™‚\")\n",
    "\n",
    "    cutoff_date = datetime.now() - timedelta(days=365*10)  # âœ… åå¹´å‰\n",
    "    for i in range(max_scroll):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        sleep(CONFIG[\"short_wait\"])\n",
    "\n",
    "        posts = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/p/']\")\n",
    "        for post in posts:\n",
    "            link = post.get_attribute(\"href\")\n",
    "            if not link or link in seen_links:\n",
    "                continue\n",
    "            seen_links.add(link)\n",
    "\n",
    "            # å˜—è©¦æŠ“æ–‡ç« æ—¥æœŸ\n",
    "            try:\n",
    "                time_el = post.find_element(By.XPATH, \".//time\")\n",
    "                date_text = time_el.get_attribute(\"datetime\") or time_el.text\n",
    "                post_date = datetime.fromisoformat(date_text.replace(\"Z\", \"+00:00\")).replace(tzinfo=None)\n",
    "            except:\n",
    "                post_date = datetime.now()\n",
    "\n",
    "            if post_date >= cutoff_date:\n",
    "                article_links.append(link)\n",
    "            else:\n",
    "                print(\"âš ï¸ å·²ç¶“é‡åˆ°è¶…éŽåå¹´çš„æ–‡ç«  â†’ åœæ­¢æ»¾å‹•\")\n",
    "                return article_links\n",
    "    return article_links\n",
    "\n",
    "# ----------------------------\n",
    "# æŠ“å–æ–‡ç« å…§å®¹ (å«è©•è«–)\n",
    "# ----------------------------\n",
    "def get_article_content(url):\n",
    "    if url in processed_links:\n",
    "        return None\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        wait = WebDriverWait(driver, CONFIG[\"wait_timeout\"])\n",
    "\n",
    "        # æ¨™é¡Œ\n",
    "        title = \"\"\n",
    "        for selector in [\"h1\", \"[data-testid='article-title']\", \"title\"]:\n",
    "            try:\n",
    "                if selector == \"title\":\n",
    "                    raw = driver.title\n",
    "                    if raw and \"Dcard\" in raw:\n",
    "                        title = raw.replace(\" | Dcard\", \"\").replace(\"- Dcard\", \"\").strip()\n",
    "                else:\n",
    "                    title_element = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, selector)))\n",
    "                    t = title_element.text.strip()\n",
    "                    if t and t != \"è«‹ç¨å€™...\":\n",
    "                        title = t\n",
    "                if title:\n",
    "                    break\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        # å…§å®¹\n",
    "        content = \"\"\n",
    "        for selector in [\"div[data-testid='post-content']\", \"article\", \".content\"]:\n",
    "            try:\n",
    "                content_element = wait.until(\n",
    "                    lambda d: d.find_element(By.CSS_SELECTOR, selector)\n",
    "                    if d.find_element(By.CSS_SELECTOR, selector).text.strip() != \"è«‹ç¨å€™...\" else False\n",
    "                )\n",
    "                text = content_element.text.strip()\n",
    "                if text and text != \"è«‹ç¨å€™...\" and len(text) > 10:\n",
    "                    content = text\n",
    "                    break\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        # æ—¥æœŸ\n",
    "        try:\n",
    "            date_element = driver.find_element(By.CSS_SELECTOR, 'time, [data-testid=\"post-date\"]')\n",
    "            date_text = date_element.get_attribute(\"datetime\") or date_element.text\n",
    "            post_date = datetime.fromisoformat(date_text.replace(\"Z\", \"+00:00\")).replace(tzinfo=None)\n",
    "        except Exception:\n",
    "            post_date = datetime.now()\n",
    "\n",
    "        # ä¸‰å¹´å…§æ–‡ç« \n",
    "        if post_date < datetime.now() - timedelta(days=365*3):\n",
    "            return None\n",
    "\n",
    "        # æŠ“è©•è«–\n",
    "        comments = []\n",
    "        try:\n",
    "            comment_elements = driver.find_elements(By.CSS_SELECTOR, 'div[data-testid=\"comment\"]')\n",
    "            for c in comment_elements:\n",
    "                txt = c.text.strip()\n",
    "                if txt:\n",
    "                    comments.append(txt)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        processed_links.add(url)\n",
    "        return {\n",
    "            \"æ¨™é¡Œ\": title,\n",
    "            \"å…§å®¹\": content,\n",
    "            \"é€£çµ\": url,\n",
    "            \"æ—¥æœŸ\": post_date.strftime(\"%Y-%m-%d\"),\n",
    "            \"è©•è«–\": \" || \".join(comments) if comments else \"\"\n",
    "        }\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# ----------------------------\n",
    "# çˆ¬å–å¤šå€‹çœ‹æ¿\n",
    "# ----------------------------\n",
    "def crawl_all_boards(boards):\n",
    "    all_links = {}\n",
    "    for board_name in boards.keys():\n",
    "        links = get_article_links(driver, board_name, CONFIG[\"max_scroll\"])\n",
    "        print(f\"âœ… {board_name} å…±ç²å– {len(links)} ç¯‡æ–‡ç« é€£çµ\")\n",
    "        all_links[board_name] = links\n",
    "\n",
    "    data_by_board = {b: [] for b in boards.keys()}\n",
    "    total_links = sum(len(v) for v in all_links.values())\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=CONFIG[\"max_workers\"]) as executor:\n",
    "        futures = []\n",
    "        for board_name, links in all_links.items():\n",
    "            for link in links:\n",
    "                futures.append((board_name, executor.submit(get_article_content, link)))\n",
    "\n",
    "        for board_name, future in tqdm(futures, total=total_links, desc=\"æŠ“å–æ–‡ç« é€²åº¦\"):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                data_by_board[board_name].append(result)\n",
    "\n",
    "    for board_name, filename in boards.items():\n",
    "        if data_by_board[board_name]:\n",
    "            pd.DataFrame(data_by_board[board_name]).to_csv(filename, index=False, encoding=\"utf-8-sig\")\n",
    "            print(f\"ðŸ“‚ {filename} å·²ä¿å­˜ {len(data_by_board[board_name])} ç¯‡æ–‡ç« \")\n",
    "\n",
    "# ----------------------------\n",
    "# ä¸»ç¨‹å¼\n",
    "# ----------------------------\n",
    "boards = {\n",
    "    \"travel\": \"æ—…éŠ.csv\",\n",
    "     \"food\": \"ç¾Žé£Ÿ.csv\",\n",
    "     \"job\": \"å·¥ä½œ.csv\",\n",
    "     \"graduate_school\": \"ç ”ç©¶æ‰€.csv\",\n",
    "     \"exam\": \"è€ƒè©¦.csv\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    crawl_all_boards(boards)\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ä¸»ç¨‹å¼éŒ¯èª¤: {e}\")\n",
    "finally:\n",
    "    driver.quit()\n",
    "    print(\"ðŸ›‘ ç€è¦½å™¨å·²é—œé–‰\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f447dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ----------------------------\n",
    "# çœ‹æ¿å°æ‡‰æª”å\n",
    "# ----------------------------\n",
    "boards = {\n",
    "    \"travel\": \"æ—…éŠ.csv\",\n",
    "     \"food\": \"ç¾Žé£Ÿ.csv\",\n",
    "     \"job\": \"å·¥ä½œ.csv\",\n",
    "    \"graduate_school\": \"ç ”ç©¶æ‰€.csv\",\n",
    "     \"exam\": \"è€ƒè©¦.csv\"\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# è¦æ¸…é™¤çš„ Dcard ç³»çµ±å­—æ¨£\n",
    "# ----------------------------\n",
    "remove_phrases = [\n",
    "    \"Dcard éœ€è¦ç¢ºèªæ‚¨çš„é€£ç·šæ˜¯å®‰å…¨çš„\"\n",
    "]\n",
    "\n",
    "# ----------------------------\n",
    "# CSV æ¸…ç†å‡½æ•¸\n",
    "# ----------------------------\n",
    "def clean_csv(file_path, output_path):\n",
    "    # å˜—è©¦è®€å– CSVï¼Œå³ä½¿æ¬„ä½æ•¸ä¸é½Šä¹Ÿè®€é€²ä¾†\n",
    "    df = pd.read_csv(file_path, on_bad_lines=\"skip\")\n",
    "\n",
    "    # ç§»é™¤ã€Œé€£çµã€æ¬„ä½\n",
    "    df_cleaned = df.drop(columns=[\"é€£çµ\"], errors=\"ignore\").copy()\n",
    "\n",
    "    # ç§»é™¤èˆŠçš„ã€Œç·¨è™Ÿã€æ¬„ä½ï¼ˆè‹¥å­˜åœ¨ï¼‰\n",
    "    if \"ç·¨è™Ÿ\" in df_cleaned.columns:\n",
    "        df_cleaned = df_cleaned.drop(columns=[\"ç·¨è™Ÿ\"])\n",
    "\n",
    "    # åŽ»æŽ‰ NaN åˆ—ï¼ˆç¼ºæ¬„ä½ã€ç©ºå€¼ï¼‰\n",
    "    df_cleaned = df_cleaned.dropna(how=\"any\")\n",
    "\n",
    "    # æ¸…ç†ã€Œæ¨™é¡Œã€ã€Œå…§å®¹ã€\n",
    "    # ç§»é™¤ã€Œè«‹ç¨å€™...ã€çš„åˆ—\n",
    "    for col in [\"æ¨™é¡Œ\", \"å…§å®¹\"]:\n",
    "        if col in df_cleaned.columns:\n",
    "            df_cleaned = df_cleaned[df_cleaned[col].str.strip() != \"è«‹ç¨å€™...\"]\n",
    "\n",
    "            df_cleaned[col] = (\n",
    "                df_cleaned[col]\n",
    "                .astype(str)\n",
    "                .str.replace(r\"\\s+\", \" \", regex=True)  # ç§»é™¤å¤šé¤˜ç©ºç™½\n",
    "                .apply(lambda x: \"\".join(x.replace(p, \"\") for p in remove_phrases))\n",
    "                .str.strip()\n",
    "            )\n",
    "\n",
    "    # ç§»é™¤æ¸…ç†å¾Œè®Šæˆç©ºå­—ä¸²çš„åˆ—\n",
    "    if \"æ¨™é¡Œ\" in df_cleaned.columns and \"å…§å®¹\" in df_cleaned.columns:\n",
    "        df_cleaned = df_cleaned[\n",
    "            (df_cleaned[\"æ¨™é¡Œ\"].str.strip() != \"\") &\n",
    "            (df_cleaned[\"å…§å®¹\"].str.strip() != \"\")\n",
    "        ]\n",
    "\n",
    "    # é‡æ–°ç”Ÿæˆæµæ°´ç·¨è™Ÿ\n",
    "    df_cleaned.insert(0, \"ç·¨è™Ÿ\", range(1, len(df_cleaned) + 1))\n",
    "\n",
    "    # è¼¸å‡ºæ¸…ç†å¾Œçš„æª”æ¡ˆ\n",
    "    df_cleaned.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"âœ… å·²è™•ç†å®Œæˆ: {output_path}\")\n",
    "\n",
    "# ----------------------------\n",
    "# æ‰¹æ¬¡è™•ç†\n",
    "# ----------------------------\n",
    "for board, filename in boards.items():\n",
    "    if os.path.exists(filename):\n",
    "        output_file = f\"{os.path.splitext(filename)[0]}.csv\"\n",
    "        clean_csv(filename, output_file)\n",
    "    else:\n",
    "        print(f\"âš ï¸ æ‰¾ä¸åˆ°æª”æ¡ˆ: {filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
