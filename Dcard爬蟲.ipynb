{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69586fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip uninstall undetected-chromedriver -y\n",
    "%pip install selenium webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6f2fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install undetected-chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef9800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8e756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ec9b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from time import sleep\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ----------------------------\n",
    "# é…ç½®åƒæ•¸\n",
    "# ----------------------------\n",
    "CONFIG = {\n",
    "    'wait_timeout': 1,\n",
    "    'short_wait': 1,\n",
    "    'medium_wait': 1,\n",
    "    'max_workers': 5,\n",
    "    'max_scroll': 1000\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# è‡ªå‹•åµæ¸¬ Chrome ä¸»ç‰ˆæœ¬\n",
    "# ----------------------------\n",
    "def get_chrome_version():\n",
    "    try:\n",
    "        version = subprocess.check_output(\n",
    "            r'reg query \"HKEY_CURRENT_USER\\Software\\Google\\Chrome\\BLBeacon\" /v version',\n",
    "            shell=True\n",
    "        ).decode('utf-8').strip().split()[-1]\n",
    "        return int(version.split('.')[0])\n",
    "    except Exception as e:\n",
    "        print('âŒ ç„¡æ³•æª¢æŸ¥ Chrome ç‰ˆæœ¬ï¼Œè«‹ç¢ºèªå·²å®‰è£ Chrome')\n",
    "        raise e\n",
    "\n",
    "chrome_major_version = get_chrome_version()\n",
    "print(f'âœ… åµæ¸¬åˆ° Chrome ä¸»ç‰ˆæœ¬è™Ÿ: {chrome_major_version}')\n",
    "\n",
    "# ----------------------------\n",
    "# å•Ÿå‹•ç€è¦½å™¨\n",
    "# ----------------------------\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--window-size=1920,1080')\n",
    "options.add_argument('--incognito')\n",
    "options.add_argument('--blink-settings=imagesEnabled=false')\n",
    "options.add_experimental_option('prefs', {\n",
    "    'profile.managed_default_content_settings.images': 2,\n",
    "    'profile.default_content_setting_values.notifications': 2\n",
    "})\n",
    "driver = uc.Chrome(version_main=chrome_major_version, options=options)\n",
    "processed_links = set()\n",
    "\n",
    "# ----------------------------\n",
    "# æŠ“å–æ–‡ç« é€£çµ\n",
    "# ----------------------------\n",
    "def get_article_links(driver, board_name, max_scroll=CONFIG['max_scroll']):\n",
    "    article_links, seen_links = [], set()\n",
    "    driver.get(f'https://www.dcard.tw/f/{board_name}')\n",
    "    try:\n",
    "        WebDriverWait(driver, CONFIG['wait_timeout']).until(\n",
    "            lambda d: d.execute_script('return document.readyState') == 'complete'\n",
    "        )\n",
    "        sleep(CONFIG['medium_wait'])\n",
    "    except TimeoutException:\n",
    "        print(f'âš ï¸ {board_name} é é¢åŠ è¼‰è¶…æ™‚')\n",
    "\n",
    "    cutoff_date = datetime.now() - timedelta(days=365*10)\n",
    "    for i in range(max_scroll):\n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "        sleep(CONFIG['short_wait'])\n",
    "        posts = driver.find_elements(By.CSS_SELECTOR, \"a[href*='/p/']\")\n",
    "        for post in posts:\n",
    "            link = post.get_attribute('href')\n",
    "            if not link or link in seen_links:\n",
    "                continue\n",
    "            seen_links.add(link)\n",
    "            try:\n",
    "                time_el = post.find_element(By.XPATH, './/time')\n",
    "                date_text = time_el.get_attribute('datetime') or time_el.text\n",
    "                post_date = datetime.fromisoformat(date_text.replace('Z', '+00:00')).replace(tzinfo=None)\n",
    "            except:\n",
    "                post_date = datetime.now()\n",
    "            if post_date >= cutoff_date:\n",
    "                article_links.append(link)\n",
    "            else:\n",
    "                return article_links\n",
    "    return article_links\n",
    "\n",
    "# ----------------------------\n",
    "# æŠ“å–æ–‡ç« å…§å®¹ (å«è©•è«–)\n",
    "# ----------------------------\n",
    "def get_article_content(url):\n",
    "    if url in processed_links:\n",
    "        return None\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        wait = WebDriverWait(driver, CONFIG['wait_timeout'])\n",
    "\n",
    "        title = ''\n",
    "        for selector in ['h1','[data-testid=\"article-title\"]','title']:\n",
    "            try:\n",
    "                if selector == 'title':\n",
    "                    raw = driver.title\n",
    "                    if raw and 'Dcard' in raw:\n",
    "                        title = raw.replace(' | Dcard','').replace('- Dcard','').strip()\n",
    "                else:\n",
    "                    t_elem = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, selector)))\n",
    "                    t = t_elem.text.strip()\n",
    "                    if t and t != 'è«‹ç¨å€™...':\n",
    "                        title = t\n",
    "                if title:\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        content = ''\n",
    "        for selector in ['div[data-testid=\"post-content\"]','article','.content']:\n",
    "            try:\n",
    "                elem = wait.until(lambda d: d.find_element(By.CSS_SELECTOR, selector)\n",
    "                                  if d.find_element(By.CSS_SELECTOR, selector).text.strip() != 'è«‹ç¨å€™...' else False)\n",
    "                text = elem.text.strip()\n",
    "                if text and len(text) > 10:\n",
    "                    content = text\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        try:\n",
    "            date_elem = driver.find_element(By.CSS_SELECTOR, 'time,[data-testid=\"post-date\"]')\n",
    "            date_text = date_elem.get_attribute('datetime') or date_elem.text\n",
    "            post_date = datetime.fromisoformat(date_text.replace('Z', '+00:00')).replace(tzinfo=None)\n",
    "        except:\n",
    "            post_date = datetime.now()\n",
    "\n",
    "        if post_date < datetime.now() - timedelta(days=365*3):\n",
    "            return None\n",
    "\n",
    "        comments = []\n",
    "        try:\n",
    "            comment_elements = driver.find_elements(By.CSS_SELECTOR,'div[data-testid=\"comment\"]')\n",
    "            for c in comment_elements:\n",
    "                txt = c.text.strip()\n",
    "                if txt:\n",
    "                    comments.append(txt)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        processed_links.add(url)\n",
    "        return {'æ¨™é¡Œ':title,'å…§å®¹':content,'é€£çµ':url,'æ—¥æœŸ':post_date.strftime('%Y-%m-%d'),'è©•è«–':' || '.join(comments) if comments else ''}\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# ----------------------------\n",
    "# ä¸»ç¨‹å¼\n",
    "# ----------------------------\n",
    "boards = {'travel':'æ—…éŠ.csv','food':'ç¾Žé£Ÿ.csv','job':'å·¥ä½œ.csv','graduate_school':'ç ”ç©¶æ‰€.csv','exam':'è€ƒè©¦.csv'}\n",
    "\n",
    "try:\n",
    "    crawl_all_boards(boards)\n",
    "except Exception as e:\n",
    "    print(f'âŒ ä¸»ç¨‹å¼éŒ¯èª¤: {e}')\n",
    "finally:\n",
    "    driver.quit()\n",
    "    print('ðŸ›‘ ç€è¦½å™¨å·²é—œé–‰')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f447dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# çœ‹æ¿å°æ‡‰æª”å\n",
    "boards = {'travel':'æ—…éŠ.csv','food':'ç¾Žé£Ÿ.csv','job':'å·¥ä½œ.csv','graduate_school':'ç ”ç©¶æ‰€.csv','exam':'è€ƒè©¦.csv'}\n",
    "\n",
    "# è¦æ¸…é™¤çš„ Dcard ç³»çµ±å­—æ¨£\n",
    "remove_phrases = ['Dcard éœ€è¦ç¢ºèªæ‚¨çš„é€£ç·šæ˜¯å®‰å…¨çš„']\n",
    "\n",
    "# CSV æ¸…ç†å‡½æ•¸\n",
    "def clean_csv(file_path, output_path):\n",
    "    df = pd.read_csv(file_path, on_bad_lines='skip')\n",
    "    df_cleaned = df.drop(columns=['é€£çµ'], errors='ignore').copy()\n",
    "    if 'ç·¨è™Ÿ' in df_cleaned.columns:\n",
    "        df_cleaned = df_cleaned.drop(columns=['ç·¨è™Ÿ'])\n",
    "    df_cleaned = df_cleaned.dropna(how='any')\n",
    "    for col in ['æ¨™é¡Œ','å…§å®¹']:\n",
    "        if col in df_cleaned.columns:\n",
    "            df_cleaned = df_cleaned[df_cleaned[col].str.strip() != 'è«‹ç¨å€™...']\n",
    "            df_cleaned[col] = df_cleaned[col].astype(str).str.replace(r'\\s+', ' ', regex=True).apply(lambda x: ''.join(x.replace(p,'') for p in remove_phrases)).str.strip()\n",
    "    if 'æ¨™é¡Œ' in df_cleaned.columns and 'å…§å®¹' in df_cleaned.columns:\n",
    "        df_cleaned = df_cleaned[(df_cleaned['æ¨™é¡Œ'].str.strip() != '') & (df_cleaned['å…§å®¹'].str.strip() != '')]\n",
    "    df_cleaned.insert(0,'ç·¨è™Ÿ',range(1,len(df_cleaned)+1))\n",
    "    df_cleaned.to_csv(output_path,index=False,encoding='utf-8-sig')\n",
    "    print(f'âœ… å·²è™•ç†å®Œæˆ: {output_path}')\n",
    "\n",
    "# æ‰¹æ¬¡è™•ç†\n",
    "for board, filename in boards.items():\n",
    "    if os.path.exists(filename):\n",
    "        output_file = f'{os.path.splitext(filename)[0]}.csv'\n",
    "        clean_csv(filename, output_file)\n",
    "    else:\n",
    "        print(f'âš ï¸ æ‰¾ä¸åˆ°æª”æ¡ˆ: {filename}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},
  "language_info": {"name":"python","version":"3.11.4"}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
